# 残る要調査項目一覧

## 🔴 最優先: 未解決の重大問題

### 1. 長い配列 (600kb+) での過剰ヒット問題
**セクション**: 13.1  
**状態**: 🔴 **未解決**  
**現象**: 
- AP027280 自己比較 (300kb): ✅ NCBI とほぼ一致 (差: 58, 0.14%)
- AP027131 vs AP027133 (600kb+): ❌ LOSAT 29,766 vs NCBI 14,871 (**約2倍**)
- 問題は配列の長さに依存（自己比較でも発生）

**根本原因**: HSP 生成数が多すぎる
- LOSAT: **338,859 HSPs** を生成
- NCBI: 推定 **30,000-45,000 HSPs**
- **約 8-11 倍の差**

**影響**:
1. 巨大チェーン形成 (400+ HSPs) → 極小 E-value
2. O(n²) 処理で **77億回操作** → 性能低下
3. 低スコアヒット (bit < 30) が NCBI の **2.5 倍** (21,708 vs 8,477)

**調査すべき箇所**:
1. ✅ `utils.rs` の two-hit ロジック → **調査完了 (NCBI と同等、セクション 4.1)**
2. ❓ `extension.rs` の X-drop 判定
3. ❓ NCBI が持つ追加のフィルタリング (seeding 段階)

**調査すべき仮説**:
- 仮説1: 長い配列での searchsp / cutoff スケーリング
- 仮説2: チェーン形成ロジックの長配列での問題
- 仮説3: cutoff_small_gap / cutoff_big_gap のスケーリング
- 仮説4: E-value 閾値付近でのフィルタリング差
- 仮説5: NCBI の追加フィルタリングロジック
- 仮説7: DPループ内のリンク条件の微妙な差異（検証済みだが要再確認）

**関連ファイル**:
- `extension.rs` - X-drop 判定
- `utils.rs` - seeding/extension ロジック
- `sum_stats_linking.rs` - チェーン形成
- `ncbi_cutoffs.rs` - cutoff 計算

---

### 2. チェーン形成の差異によるE-value不整合
**セクション**: 11.1  
**状態**: 🔶 **コード比較完了、実動作調査が必要**  
**現象**: 
- NZ_CP006932 自己比対: LOSAT 95,188 vs NCBI 62,053 (+53%)
- 異常なE-value: bit_score=22.1 なのに E-value=1.3e-114

**根本原因の推定**:
- 短いHSPが本来リンクされるべきでない高スコアチェーンにリンクされている
- 同じ8AAのHSPが:
  - **NCBI**: 単独HSPまたは小さいチェーン → E-value ≈ 8-9
  - **LOSAT**: 高スコアチェーンに誤ってリンク → E-value = 1.3e-114

**調査結果 (2026-01-XX)**:

#### 2.1 リンキング条件の比較 ✅
**NCBIコード参照**:
- `link_hsps.c:702-746` (INDEX 0: small gap)
- `link_hsps.c:795-861` (INDEX 1: large gap)

**LOSATコード**:
- `sum_stats_linking.rs:1020-1047` (INDEX 0)
- `sum_stats_linking.rs:1110-1160` (INDEX 1)

**確認結果**:
1. ✅ `score > cutoff[index]` 条件の適用タイミング: NCBIと一致
2. ✅ INDEX 0 のリンク条件: `qo <= h_qe || so <= h_se || qo > h_qe_gap || so > h_se_gap` - NCBI `if (b1|b2|b5|b4) continue;` と等価
3. ✅ INDEX 1 のリンク条件: `!(b0 || b1 || b2)` - NCBI `if (!(b0|b1|b2))` と等価
4. ✅ 早期終了条件: INDEX 0で `qo > h_qe_gap + TRIM_SIZE` のbreak条件が一致

#### 2.2 座標計算の比較 ✅
**NCBIコード**:
- `link_hsps.c:545-550`: `q_length = (hsp->query.end - hsp->query.offset) / 4;`
- `H->q_offset_trim = hsp->query.offset + MIN(q_length, trim_size);`

**LOSATコード**:
- `sum_stats_linking.rs:782-799`: `q_len_quarter = (q_end - q_off) / 4;`
- `qt = TRIM_SIZE.min(q_len_quarter);`
- `q_off_trim: q_off + qt`

**確認結果**: ✅ trim座標計算はNCBIと完全一致

#### 2.3 Cutoff値の計算 ✅
**NCBIコード**: `blast_parameters.c:998-1082` - `CalculateLinkHSPCutoffs`
**LOSATコード**: `sum_stats_linking.rs:302-401` - `calculate_link_hsp_cutoffs_ncbi`

**確認結果**: ✅ cutoff計算式はNCBIと完全一致（既に実装済み）

#### 2.4 ソート順序の確認 ✅
**NCBIコード**: `link_hsps.c:359-374` - `s_RevCompareHSPsTbx` (全フィールド降順)
**LOSATコード**: `sum_stats_linking.rs:533-561` (全体ソート), `684-691` (グループ内ソート)

**確認結果**: ✅ ソート順序はNCBIと完全一致（既に実装済み）

#### 2.5 定数値の確認 ✅
- `WINDOW_SIZE = GAP_SIZE + OVERLAP_SIZE + 1 = 40 + 9 + 1 = 50` ✅
- `TRIM_SIZE = (OVERLAP_SIZE + 1) / 2 = (9 + 1) / 2 = 5` ✅
- NCBIコードでも同じ計算式を使用 ✅

**結論**:
- **コードレベルではNCBIと完全一致**を確認
- リンキング条件、座標計算、cutoff値、ソート順序は全てNCBIと同等
- **修正完了**: `xsum`の更新順序をNCBIと一致させるよう修正（`best`更新の後）
- **実動作での差異の原因はコード実装ではなく、データ処理のタイミングや浮動小数点精度の可能性**

**次のステップ**:
1. ✅ デバッグ出力を追加: 具体的なHSP（座標 635385-635362、8AA、bit_score=22.1）がどのチェーンに所属するかトレース
2. ✅ 実際のリンキング決定時の条件判定をログ出力（実装済み）
3. ⏳ NCBI出力とLOSAT出力で同じHSPが異なるチェーンに属する原因を特定（デバッグ出力で調査可能）

**デバッグ出力の使い方**:
環境変数 `LOSAT_DEBUG_CHAINING=1` を設定して実行すると、問題のHSP（座標635385-635362）のリンキング処理を詳細にトレースします。

出力内容:
- ターゲットHSPの検出と初期情報（座標、スコア、cutoff値との比較）
- INDEX 0 (small gap) と INDEX 1 (large gap) のリンキング決定過程
- 各候補HSPとの距離チェック結果
- リンク先HSPの情報
- チェーンへの所属とE-valueの継承

実行例:
```bash
LOSAT_DEBUG_CHAINING=1 losat tblastx -query NZ_CP006932.fa -subject NZ_CP006932.fa -outfmt 6 > output.txt 2> debug.log
```

**関連ファイル**:
- `sum_stats_linking.rs` - リンキングロジック
- `ncbi_cutoffs.rs` - cutoff 計算
- NCBI `link_hsps.c:719-724` - リンキング条件

---

## 🔶 中優先: 詳細調査が必要な項目

### 3. ✅ Extension の X-drop 判定
**セクション**: 13.1 (仮説8関連)  
**状態**: ✅ **調査完了** (2026-01-04)  
**結論**: **X-drop 終了条件は NCBI と完全に一致。コード修正不要。**

**調査結果**:
- NCBI `s_BlastAaExtendLeft` (`aa_ungapped.c:886-921`) と LOSAT left extension (`extension.rs:228-252`) を1行ずつ比較
- NCBI `s_BlastAaExtendRight` (`aa_ungapped.c:831-866`) と LOSAT right extension (`extension.rs:272-293`) を1行ずつ比較
- **終了条件**: `(maxscore - score) >= dropoff` vs `(max_score - current_score) >= x_drop` - **完全一致**
- **負スコアチェック**: Right extension で `score <= 0` の早期終了が実装済み - **NCBI と同等**
- **ループ境界**: LOSAT の境界チェックは NCBI と同等
- **長い配列での動作**: X-drop 判定は NCBI と完全一致しており、過剰ヒット問題の原因ではない

**関連ファイル**:
- `extension.rs` - extension ロジック
- NCBI `aa_ungapped.c:831-866, 886-921` - extension 関数
- `TBLASTX_NCBI_PARITY_STATUS.md` セクション 3.6 - 詳細比較結果

---

### 4. ✅ Seeding 段階の追加フィルタリング
**セクション**: 13.1 (仮説8関連)  
**状態**: ✅ **調査完了** (2026-01-05)  
**結論**: **Seeding段階での追加フィルタリングは見つからなかった。LOSATとNCBIの実装は同等。**

**調査結果**:

#### 4.1 NCBIのseeding段階のフィルタリングフロー

NCBI BLASTのseeding段階は以下の順序で処理される：

1. **`s_BlastAaScanSubject`** (blast_aascan.c:48-131)
   - Lookup tableからword matchesを取得
   - **追加のフィルタリングなし** - 単純にhitsを返すだけ

2. **`s_BlastAaWordFinder_TwoHit`** (aa_ungapped.c:440-619)
   - Two-hit条件チェック：
     - `flag`チェック（既にextendしたかどうか）
     - `window`チェック（`diff >= window`）
     - `wordsize`チェック（`diff < wordsize`）
     - `context`チェック（`query_offset - diff < query_info->contexts[curr_context].query_offset`）
   - 条件を満たした場合のみ`s_BlastAaExtendTwoHit`を呼び出す

3. **`s_BlastAaExtendTwoHit`** (aa_ungapped.c:1089-1158)
   - Two-hit ungapped extensionを実行

4. **`BlastSaveInitHsp`** (blast_extend.c:360)
   - HSPを保存（`score >= cutoffs->cutoff_score`の場合のみ）

5. **`Blast_HSPListReevaluateUngapped`** (blast_engine.c:1493, blast_hits.c:2609-2736)
   - Linkingの**前**に全HSPをreevaluate
   - `Blast_HSPReevaluateWithAmbiguitiesUngapped`を各HSPに適用
   - `Blast_HSPTest`でidentity/lengthチェック（`s_HSPTest`）

#### 4.2 LOSATのseeding段階のフィルタリングフロー

LOSATのseeding段階は以下の順序で処理される：

1. **`s_blast_aa_scan_subject`** (utils.rs:793-799)
   - Lookup tableからword matchesを取得
   - NCBIと同等

2. **Two-hit条件チェック** (utils.rs:831-889)
   - `flag`チェック
   - `window`チェック
   - `wordsize`チェック
   - `context`チェック
   - **NCBIと完全に同等**

3. **`extend_hit_two_hit`** (extension.rs:192-)
   - Two-hit ungapped extensionを実行
   - NCBIと同等

4. **`reevaluate_ungapped_hit_ncbi_translated`** (utils.rs:987, reevaluate.rs:80-145)
   - Extension直後にreevaluate（NCBIとはタイミングが異なるが機能的には同等）
   - NCBIの`Blast_HSPReevaluateWithAmbiguitiesUngapped`と同等のロジック

5. **HSP保存** (utils.rs:1007-1025)
   - `score >= cutoff`の場合のみ保存

#### 4.3 相違点の分析

##### タイミングの違い（機能的には同等）
- **NCBI**: Extension → Save → 一括Reevaluate → `Blast_HSPTest`
- **LOSAT**: Extension → Reevaluate → Save

**分析**: タイミングは異なるが、機能的には同じ結果になる。ただし、NCBIは`Blast_HSPTest`（identity/lengthチェック）をreevaluation後に実行している。

##### `Blast_HSPTest`の実装有無

NCBIの`Blast_HSPTest`（blast_hits.c:993-999）は以下をチェック：
```c
return ((hsp->num_ident * 100.0 < align_length * hit_options->percent_identity) ||
        align_length < hit_options->min_hit_length);
```

**調査結果**: 
- `BlastHitSavingOptionsNew`は`calloc`で初期化するため、デフォルトでは`percent_identity = 0.0`、`min_hit_length = 0`
- この場合、`s_HSPTest`は常にfalseを返し、フィルタリングは**実質的に無効**
- LOSATにはこのチェックは実装されていないが、デフォルトでは影響なし

#### 4.4 Lookup table構築時のフィルタリング

**LOSAT**: `max_hits_per_kmer`パラメータでover-represented k-mersをフィルタリング（lookup.rs:623-625）
- `max_hits_per_kmer = 50000`を超えるk-mersを除外
- コメントには「This mimics NCBI's approach」とあるが、**実際にはNCBIにはこのフィルタリングは存在しない**

**NCBI**: 
- `BlastLookupAddWordHit` (blast_lookup.c:33-77) は単純にhitを追加するだけ
- チェーンサイズが足りなくなったら`realloc`で拡張するのみ
- **over-represented k-mersのフィルタリングは実装されていない**

**結論**: LOSATの`max_hits_per_kmer`フィルタリングは**NCBIには存在しない追加機能**。これが過剰ヒット問題の原因の可能性がある。NCBIは全てのk-mersを保持するため、LOSATがフィルタリングすることで結果に差異が生じる可能性がある。

**NCBIが実装するlookup table構築時のフィルタリング**:

NCBIのprotein lookup table構築時には、以下のフィルタリングが実装されています：

1. **SEGマスキング** (`blast_aalookup.c`):
   - SEGマスクされた領域のwordはスキップされる
   - LOSATでも実装済み（`lookup.rs:337-342`）

2. **Thresholdベースのフィルタリング** (`blast_aalookup.c:504-514`):
   - Wordのself-scoreがthreshold未満の場合のみ、exact matchをlookup tableに追加
   - Threshold以上の場合、neighbor wordsを探索（exact matchは追加しない）
   - LOSATでも実装済み（`lookup.rs:472-515`）

3. **無効な残基（invalid residue）のスキップ** (`lookup.rs:352-355`):
   - アルファベットサイズ（28）を超える残基を含むwordはスキップ
   - LOSATでも実装済み

4. **曖昧な文字（ambiguity）を含むwordのスキップ** (`blast_lookup.c:117-120`):
   - これは**nucleotide lookup用**（`BlastLookupIndexQueryExactMatches`）
   - Protein lookupでは使用されない

5. **pv_arrayフィルタリング** (`blast_lookup.c:189-193`):
   - これは**nucleotide lookup用**（`s_AddWordHit`）で、protein lookupでは使用されない

**重要な点**:
- **`max_hits_per_kmer`のようなフィルタリングはNCBIには存在しない**
- NCBIは全てのvalidなk-mersを保持する（SEGマスクやthresholdによる除外を除く）
- Over-represented k-mersのフィルタリングは実装されていない

---

### 5. ✅ NCBIの過剰ヒット防止メカニズム
**セクション**: 13.1 (仮説8関連)  
**状態**: ✅ **調査完了** (2026-01-05)  
**結論**: **NCBIは主にcutoff計算によって過剰ヒットを防いでいる。HSP数制限や追加フィルタリングはデフォルトでは無効。**

**調査結果**:

#### 5.1 Cutoff計算によるフィルタリング
- **NCBI**: `cutoff_score_max`を`eff_searchsp`から計算（`blast_parameters.c:926, 943`）
  - `searchsp = query_info->contexts[context].eff_searchsp`
  - `BLAST_Cutoffs(&new_cutoff, &evalue, kbp, searchsp, FALSE, 0)`
  - tblastxでは`kbp_gap`がNULLのため、**ungapped params (kbp)**を使用
- **最終的なcutoff**: `MIN(update_cutoff, gap_trigger, cutoff_score_max)`
  - `update_cutoff`: `CUTOFF_E_TBLASTX = 1e-300`から計算（通常1または非常に低い値）
  - `gap_trigger = 41` (BLOSUM62の場合)
  - `cutoff_score_max`: ユーザーのE-value (10.0) と`eff_searchsp`から計算
- **長い配列での挙動**:
  - `eff_searchsp`が大きくなる → `cutoff_score_max`が高くなる可能性
  - しかし、最終的なcutoffは`MIN(...)`で決定されるため、`gap_trigger = 41`が支配的になることが多い

#### 5.2 HSP数制限
- **NCBI**: `max_hsps_per_subject`パラメータが存在（`blast_hits.c:2049-2069`）
  - デフォルト値: **0（無制限）**
  - `Blast_TrimHSPListByMaxHsps`で制限を適用可能だが、デフォルトでは無効
- **結論**: HSP数制限は**デフォルトでは無効**のため、過剰ヒット防止の主要メカニズムではない

#### 5.3 Reevaluation後のフィルタリング
- **NCBI**: `Blast_HSPListReevaluateUngapped`でreevaluation後に`Blast_HSPTest`を呼ぶ（`blast_hits.c:2719`）
  - `Blast_HSPTest`: percent identityとminimum hit lengthをチェック
  - デフォルト値: `percent_identity = 0`, `min_hit_length = 0`（`calloc`初期化）
  - **結論**: デフォルトでは**実質的に無効**

#### 5.4 その他のフィルタリング
- **Culling**: tblastxではデフォルトで無効（`blast_options.c:869`）
- **Domination filter**: tblastxではデフォルトで無効
- **Lookup tableフィルタリング**: NCBIには`max_hits_per_kmer`のようなフィルタリングは存在しない

#### 5.5 結論
**NCBIが過剰ヒットを防ぐ主要メカニズムはcutoff計算**:
1. `cutoff_score_max`を`eff_searchsp`から計算
2. 最終的なcutoffを`MIN(update_cutoff, gap_trigger, cutoff_score_max)`で決定
3. `gap_trigger = 41`が支配的になることが多い

**長い配列での挙動**:
- `eff_searchsp`が大きくなる → `cutoff_score_max`が高くなる可能性
- しかし、最終的なcutoffは`MIN(...)`で決定されるため、`gap_trigger = 41`が支配的になることが多い
- **もし`cutoff_score_max`が`gap_trigger`より低い場合、より多くのHSPが通過する可能性がある**

**LOSATとの比較**:
- LOSATも同様のcutoff計算を実装している
- しかし、`max_hits_per_kmer`フィルタリングがNCBIには存在しない
- **過剰ヒット問題の原因は、cutoff計算の差異ではなく、他の要因（例: lookup table構築時のフィルタリング）の可能性が高い**

**関連ファイル**:
- NCBI `blast_parameters.c:734-994` - `BlastHitSavingParametersNew`
- NCBI `blast_parameters.c:348-374` - `BlastInitialWordParametersUpdate` (per-subject update)
- NCBI `blast_hits.c:2049-2069` - `Blast_TrimHSPListByMaxHsps`
- NCBI `blast_hits.c:2609-2737` - `Blast_HSPListReevaluateUngapped`
- LOSAT `ncbi_cutoffs.rs` - cutoff計算関数

#### 4.5 Subject scanningの制限

**`offset_array_size`の計算**:
- LOSAT: `OFFSET_ARRAY_SIZE (4096) + lookup.longest_chain` (utils.rs:638-639)
- NCBI: `OFFSET_ARRAY_SIZE (4096) + lookup->longest_chain`
- **完全に同等**

**早期終了条件**:
- LOSAT: `numhits <= array_size - totalhits` (utils.rs:175)
- NCBI: `numhits <= (array_size - totalhits)` (blast_aascan.c:96)
- **完全に同等**

#### 4.6 結論

**Seeding段階での追加フィルタリングは見つからなかった。** LOSATとNCBIの実装は同等であり、過剰ヒット問題（338,859 vs 30,000-45,000 HSPs）の原因はseeding段階のフィルタリングではない。

**過剰ヒット問題の原因は別の箇所にある可能性が高い**:
- Extension段階でのX-drop判定（既に調査済み、NCBIと同等）
- Cutoff計算の差異（既に調査済み、NCBIと同等）
- 他の段階でのフィルタリングロジック

**関連ファイル**:
- `utils.rs` - seeding ロジック
- `lookup.rs` - lookup table構築
- `reevaluate.rs` - HSP reevaluation
- NCBI `blast_aascan.c` - subject scanning
- NCBI `aa_ungapped.c` - word finding
- NCBI `blast_hits.c` - reevaluation and HSP test

---

## 📝 低優先度: 技術的確認項目

### 5. ✅ E-value計算の数値精度
**セクション**: 13.2.2 (仮説4)  
**状態**: ✅ **調査完了・修正完了** (2026-01-XX)  
**結論**: **数値精度はNCBIと完全一致。重要な修正を実施。**

**調査結果**:
- ✅ `small_gap_sum_e()` の計算順序はNCBIと完全一致
- ✅ `uneven_gap_sum_e()` の計算順序はNCBIと完全一致
- ✅ `large_gap_sum_e()` の計算順序はNCBIと完全一致
- ✅ `xsum` 累積はNCBIと同等の方法で実装されており、精度問題なし
- ✅ `ln_factorial_int()` は直接計算を使用（NCBIは`lgamma`使用）が、テスト結果から十分な精度を確認
- ✅ `blast_sum_p()` のRomberg積分パラメータはNCBIと一致
- ✅ `p_to_e()` と `e_to_p()` はNCBIと同等の実装（`ln_1p`と`exp_m1`を使用）

**重要な修正**:
- 🔧 **`weight_divisor`の処理を修正**: 3つの関数すべてで、NCBIと完全に一致するように修正
  - **修正前**: `sum_e / weight_divisor`を計算してチェックしてから実行
  - **修正後**: `sum_e /= weight_divisor`を実行してからチェック（NCBIと同一）
  - 影響範囲: `small_gap_sum_e()`, `uneven_gap_sum_e()`, `large_gap_sum_e()`

**テスト結果**:
- 小さいチェーン (2-10 HSPs): 相対誤差 < 1e-10 ✅
- 中程度のチェーン (50-100 HSPs): 相対誤差 < 1e-4 ✅
- 長いチェーン (400+ HSPs): 相対誤差 < 1e-4 ✅
- `xsum` 累積: 相対誤差 < 1e-10 ✅
- `p_to_e`/`e_to_p` ラウンドトリップ: 相対誤差 < 1e-10 ✅
- `weight_divisor`処理: NCBIと完全一致 ✅

**関連ファイル**:
- `src/stats/sum_statistics.rs` - sum statistics 計算（修正済み）
- `tests/unit/stats/evalue_precision.rs` - 数値精度テスト
- `tests/unit/stats/evalue_precision_fix_verification.rs` - weight_divisor修正の検証テスト
- NCBI `blast_stat.c:4418-4463, 4491-4522, 4532-4573` - sum statistics 実装

---

### 6. ✅ 座標システムの off-by-one エラー
**セクション**: 13.2.2 (仮説2)  
**状態**: ✅ **調査完了 (2026-01-04)**  
**結論**: **座標システムにoff-by-oneエラーは発見されず。すべての座標変換はNCBIと一致。**

**調査結果**:

1. **Extension結果の座標計算** (`extension.rs:298-301`):
   - LOSAT: `q_start = q_right_off - left_disp`, `q_end = q_right_off + right_disp`
   - NCBI: `hsp_q = q_right_off - left_d`, `hsp_len = left_d + right_d`
   - 検証: `q_end - q_start = left_disp + right_disp = hsp_len` → **一致** ✅

2. **Sentinelバイトの処理** (`utils.rs:1002-1003`, `utils.rs:1143-1144`):
   - Extension結果（raw座標）からlogical座標: `qs_l = qs.saturating_sub(1)`
   - Logical座標からraw座標への復元: `q0 = h.q_aa_start + 1`
   - 検証: 変換が一貫しており、off-by-oneエラーなし ✅

3. **AA座標からDNA座標への変換** (`extension.rs:717-730`):
   - Forward frame: `start_bp = aa_start * 3 + shift + 1`, `end_bp = aa_end * 3 + shift`
   - Reverse frame: `start_bp = dna_len - (aa_start * 3 + shift)`, `end_bp = dna_len - (aa_end * 3 + shift - 1)`
   - 検証: ドキュメント（セクション3.2）でNCBIと一致を確認済み ✅

4. **Frame内相対座標の計算** (`utils.rs:881`, `sum_stats_linking.rs:675-677`):
   - LOSAT: `q_raw = (query_offset - ctx.frame_base) as usize` → `hit.q_aa_start` (既にframe内相対座標)
   - NCBI: `s_AdjustInitialHSPOffsets` で `q_start -= query_start` (frame内相対座標に変換)
   - 検証: ドキュメント（セクション3.2）で修正済み、NCBIと一致 ✅

5. **エッジケースの検証**:
   - `aa_start = 0`: Forward `start_bp = 1`, Reverse `start_bp = dna_len` → **正しい** ✅
   - `aa_end = aa_len`: Forward `end_bp = aa_len * 3`, Reverse `end_bp = dna_len - (aa_len * 3 - 1)` → **正しい** ✅
   - Reverse frame (`start > end`): frame=-1, aa_start=0, aa_end=2, dna_len=12 → (12, 7) → **正しい** ✅
   - Sentinel境界: `qs.saturating_sub(1)` で正しく処理 → **正しい** ✅

**関連ファイル**:
- `extension.rs` - Extensionと座標変換
- `utils.rs` - 座標変換とsentinel処理
- `sum_stats_linking.rs` - リンキング時の座標使用
- NCBI `aa_ungapped.c` - Extension実装
- NCBI `blast_gapalign.c` - 座標調整

---

## まとめ

### 優先度順

1. **🔴 最優先**: 長い配列 (600kb+) での過剰ヒット問題
   - HSP 生成数が多すぎる (338,859 vs 30,000-45,000)
   - ✅ Extension の X-drop 判定: 調査完了 (NCBI と完全一致、原因ではない)
   - Seeding 段階のフィルタリングを調査

2. **🔴 最優先**: チェーン形成の差異によるE-value不整合
   - 短いHSPが高スコアチェーンに誤ってリンク
   - リンキング条件、座標比較、cutoff値の差異を調査

3. ~~**🔶 中優先**: Extension の X-drop 判定~~ → ✅ **調査完了 (2026-01-04)**
   - X-drop 終了条件は NCBI と完全一致。過剰ヒット問題の原因ではない

4. **🔶 中優先**: Seeding 段階の追加フィルタリング
   - NCBI の追加フィルタリングの有無を確認

5. ~~**📝 低優先度**: E-value計算の数値精度~~ → ✅ **調査完了 (2026-01-XX)**
   - 数値精度はNCBIと同等。長いチェーン（400+ HSPs）でも許容範囲内の精度を維持。修正不要。

6. **📝 低優先度**: 座標システムの off-by-one エラー
   - エッジケースでの座標計算の検証

---

## 調査済み・修正済み項目（参考）

✅ 完了済み:
- Two-hit Window 詳細 (4.1)
- Lookup Table 構築詳細 (4.2)
- Masked Region Extension 処理 (4.3)
- HSP 重複排除 (Culling) (4.4)
- Context 別 Karlin パラメータ (4.5)
- BSearchContextInfo 検索 (4.6)
- Extension スコア計算 (4.7)
- Sum-Statistics Linking チェイン構造 (4.8)
- Reverse strand 処理 (4.9)
- E-value 閾値判定 (4.10)
- チェーンメンバー出力フィルタリング (11.2)
- eff_searchsp 事前計算 (仮説6)

